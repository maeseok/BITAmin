{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 09-1 순차 데이터와 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#순차 데이터 : 텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터\n",
    "#피드포워드 신경망 : 입력 데이터의 흐름이 앞으로만 전달되는 신경망 (합성곱, 완전 연결 신경망)\n",
    "#순환 신경망 : 뉴런의 출력이 자기 자신에게 다시 전달됨. (순차 데이터)\n",
    "#타임스텝 : 이전 샘플에 대한 기억을 가지고 있는 과정을 처리하는 한 단계\n",
    "#셀 : 순환 신경망에서의 층, 뉴런을 모두 표시하지 않고 하나의 셀로 층을 표현\n",
    "#은닉 상태 : 셀의 출력\n",
    "#셀(순환층) -> 활성화 함수(일반적으로 탄젠트 함수) -> 은닉 상태\n",
    "#순환 신경망의 뉴런은 입력과 가중치와 이전 타임스텝의 은닉 상태에 곱해지는 가중치 -> 현재 타입스텝의 은닉 상태\n",
    "#순환층은 일반적으로 샘플마다 2개의 차원을 가진다.\n",
    "#보통 하나의 샘플을 하나의 시퀀스라고 한다. 시퀀스의 길이는 타임스텝 길이이다.\n",
    "#순환층은 기본적으로 마지막 타임스텝의 은닉 상태만 출력으로 내보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 09-2 순환 신경망으로 IMDB 리뷰 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰 : 분리된 단어 (NLP), 1개의 토큰은 하나의 타임스텝\n",
    "from tensorflow.keras.datasets import imdb\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=300) #자주 등장하는 단어 300개만\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "218\n",
      "189\n",
      "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 2, 284, 5, 150, 4, 172, 112, 167, 2, 2, 2, 39, 4, 172, 2, 2, 17, 2, 38, 13, 2, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 2, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 2, 12, 8, 2, 8, 106, 5, 4, 2, 2, 16, 2, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 2, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 7, 4, 2, 2, 13, 104, 88, 4, 2, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 2, 26, 2, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, test_input.shape)\n",
    "print(len(train_input[0])) #첫 번째 리뷰의 길이\n",
    "print(len(train_input[1])) #두 번째 리뷰의 길이\n",
    "print(train_input[0]) #첫 번째 리뷰에 담긴 내용\n",
    "#어휘 사전에 없는 단어는 2로 표시됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[:20]) #긍정 1 부정 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.00925 178.0\n"
     ]
    }
   ],
   "source": [
    "#각 리뷰의 길이를 계산해 저장 (리뷰의 길이 확인학 싶어서)\n",
    "import numpy as np\n",
    "lengths = np.array([len(x) for x in train_input])\n",
    "print(np.mean(lengths), np.median(lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100개의 단어만 사용, 이 보다 작은 리뷰는 패딩으로 채움, 길면 잘름\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = pad_sequences(train_input, maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   4  20   9   2   2   2   5  45   6   2   2  33 269   8   2 142   2\n",
      "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
      "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
      "   2   7   2   2 188   2 103  14  31  10  10   2   7   2   5   2  80  91\n",
      "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
      "   6   2  46   7  14  20  10  10   2 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 46, 7, 14, 20, 10, 10, 2, 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2   2   2 183  10\n",
      "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
      "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
      "   2  95  14 238  56 129   2  10  10  21   2  94   2   2   2   2  11 190\n",
      "  24   2   2   7  94 205   2  10  10  87   2  34  49   2   7   2   2   2\n",
      "   2   2 290   2  46  48  64  18   4   2]\n"
     ]
    }
   ],
   "source": [
    "#샘플의 앞 부분이 잘렸다는 것을 짐작할 수 있음\n",
    "\n",
    "#채워지는 것도 앞부분으로 0 \n",
    "print(train_seq[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증 세트의 길이도 100\n",
    "val_seq = pad_sequences(val_input, maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN(순환신경망) 만들기\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "#샘플 길이 100, 원-핫 인코딩 300개 단어\n",
    "model.add(keras.layers.SimpleRNN(8, input_shape = (100,300)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100, 300)\n"
     ]
    }
   ],
   "source": [
    "#원-핫 인코딩\n",
    "train_oh = keras.utils.to_categorical(train_seq)\n",
    "print(train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_oh[0][0][:12]) #첫 번째 샘플의 첫 번째 토큰 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_oh[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_oh = keras.utils.to_categorical(val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 8)                 2472      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2481 (9.69 KB)\n",
      "Trainable params: 2481 (9.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.4999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gudtj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 35s 94ms/step - loss: 0.6997 - accuracy: 0.4999 - val_loss: 0.6958 - val_accuracy: 0.5140\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 16s 51ms/step - loss: 0.6967 - accuracy: 0.5059 - val_loss: 0.6940 - val_accuracy: 0.5226\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.6944 - accuracy: 0.5101 - val_loss: 0.6925 - val_accuracy: 0.5266\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 17s 53ms/step - loss: 0.6925 - accuracy: 0.5153 - val_loss: 0.6912 - val_accuracy: 0.5330\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6909 - accuracy: 0.5238 - val_loss: 0.6900 - val_accuracy: 0.5402\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.6893 - accuracy: 0.5316 - val_loss: 0.6886 - val_accuracy: 0.5460\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.6876 - accuracy: 0.5397 - val_loss: 0.6872 - val_accuracy: 0.5532\n",
      "Epoch 8/100\n",
      "177/313 [===============>..............] - ETA: 5s - loss: 0.6869 - accuracy: 0.5459"
     ]
    }
   ],
   "source": [
    "#순환 신경망 훈련하기\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_oh, train_target, epochs=100, batch_size=64,\n",
    "                    validation_data=(val_oh, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#원-핫 인코딩의 단점은 입력 데이터가 엄청 커진다는 것이다.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_seq\u001b[49m\u001b[38;5;241m.\u001b[39mnbytes, train_oh\u001b[38;5;241m.\u001b[39mnbytes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_seq' is not defined"
     ]
    }
   ],
   "source": [
    "#원-핫 인코딩의 단점은 입력 데이터가 엄청 커진다는 것이다.\n",
    "print(train_seq.nbytes, train_oh.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           4800      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 8)                 200       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5009 (19.57 KB)\n",
      "Trainable params: 5009 (19.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#단어 임베딩 : 각 단어를 고정된 크기의 실수 벡터로 변경\n",
    "#입력으로 정수 데이터를 받아 train_seq 사용 가능\n",
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(keras.layers.Embedding(300, 16, input_length=100))\n",
    "model2.add(keras.layers.SimpleRNN(8))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model2.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                     validation_data=(val_seq, val_target),\n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()\n",
    "#성능은 비슷한데 속도는 단어 임베딩 > 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chpater 09-3 LSTM과 GRU 셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM : 단기 기억을 오래 기억하기 위해 사용\n",
    "#입력과 가중치를 곱하고 절편을 더해 활성화 함수를 통과시키는 구조 여러 개 보유\n",
    "#은닉 상태는 입력과 이전 타입스텝의 은닉 상태를 가중치에 곱한 후 활성화 함수 통과\n",
    "#활성화 함수는 시그모이드 함수 -> tanh 함수\n",
    "#LSTM에는 순환되는 상태가, 은닉상태, 셀 상태 2개이다.\n",
    "#셀 상태는 다음 층으로 전달되지 않고 LSTM 셀에서 순환만 되는 값\n",
    "#셀 상태는 입력과 은닉 상태를 또 다른 가중치 W에 곱한 다음 시그모이드 함수 통과\n",
    "#이후 이전 타임스텝의 셀 상태와 곱하여 새로운 셀 상태를 만든다.\n",
    "#이 셀 상태가 오른쪽에서 tanh 함수를 통과하여 새로운 은닉 상태를 만드는 데 기여\n",
    "\n",
    "#삭제 게이트 : 셀 상태에 있는 정보를 제거하는 역할\n",
    "#입력 게이트 : 새로운 정보를 셀 상태에 추가\n",
    "#출력 게이트 : 이 셀 상태가 다음 은닉 상태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행마다 동일한 결과를 얻기 위해 케라스에 랜덤 시드를 사용하고 텐서플로 연산을 결정적으로 만듭니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data(\n",
    "    num_words=500)\n",
    "\n",
    "train_input, val_input, train_target, val_target = train_test_split(\n",
    "    train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_seq = pad_sequences(train_input, maxlen=100)\n",
    "val_seq = pad_sequences(val_input, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 800       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8809 (34.41 KB)\n",
      "Trainable params: 8809 (34.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(500, 16, input_length=100))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                    validation_data=(val_seq, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#순환층에 드롭아웃 적용하기 (과대적합 제어)\n",
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(keras.layers.Embedding(500, 16, input_length=100))\n",
    "model2.add(keras.layers.LSTM(8, dropout=0.3))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model2.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-dropout-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                     validation_data=(val_seq, val_target),\n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()\n",
    "#검증 손실 약간 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 8)            800       \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9353 (36.54 KB)\n",
      "Trainable params: 9353 (36.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#2개의 층을 연결\n",
    "model3 = keras.Sequential()\n",
    "\n",
    "model3.add(keras.layers.Embedding(500, 16, input_length=100))\n",
    "#마지막을 제외한 순환층은 모든 타임스탭에 대한 은닉 상태를 출력\n",
    "model3.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True))\n",
    "#마지막 순환층은 마지막 타임스텝의 은닉 상태를 출력\n",
    "model3.add(keras.layers.LSTM(8, dropout=0.3))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model3.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-2rnn-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model3.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                     validation_data=(val_seq, val_target),\n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()\n",
    "#과대적합을 제어하면서 손실을 최대한 낮춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 8)                 624       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8633 (33.72 KB)\n",
      "Trainable params: 8633 (33.72 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#GRU : LSTM 간소화 버전, 셀 상태를 계산하지 않고 은닉 상태 하나만 포함\n",
    "#LSTM보다 계산량 적지만 성능은 비슷\n",
    "model4 = keras.Sequential()\n",
    "\n",
    "model4.add(keras.layers.Embedding(500, 16, input_length=100))\n",
    "model4.add(keras.layers.GRU(8))\n",
    "model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model4.compile(optimizer=rmsprop, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-gru-model.h5',\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model4.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
    "                     validation_data=(val_seq, val_target),\n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at best-2rnn-model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#테스트 세트 성능 계산\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_seq \u001b[38;5;241m=\u001b[39m pad_sequences(test_input, maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m rnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest-2rnn-model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m rnn_model\u001b[38;5;241m.\u001b[39mevaluate(test_seq, test_target)\n",
      "File \u001b[1;32mc:\\Users\\gudtj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gudtj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\gudtj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at best-2rnn-model.h5"
     ]
    }
   ],
   "source": [
    "#테스트 세트 성능 계산\n",
    "test_seq = pad_sequences(test_input, maxlen=100)\n",
    "\n",
    "rnn_model = keras.models.load_model('best-2rnn-model.h5')\n",
    "\n",
    "rnn_model.evaluate(test_seq, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
