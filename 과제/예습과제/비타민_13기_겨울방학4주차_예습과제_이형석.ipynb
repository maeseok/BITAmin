{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 프레임워크(Deep Learning Framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 딥러닝 프레임워크 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 다음 빈 칸에 들어갈 알맞은 말을 써넣어주세요. <br>\n",
    "- (a)(이)란 여러 층을 가진 인공신경망을 사용하여(Artificial Neural Network)을 사용하여 머신러닝 학습을 수행하는 것으로 심층학습이라고도 불린다.\n",
    "- (b)(이)란 응용 프로그램을 개발하기 위한 여러 라이브러리나 모듈 등을 효율적으로 사용할 수 있도록 하나로 묶어 놓은 일종의 패키지이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 (a) : 딥러닝   , (b) : 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 다음 빈 칸에 공통으로 들어갈 알맞은 말을 써넣어주세요. <br>\n",
    "- (    )(이)란 딥러닝 모델을 쉽게 구현하고 학습할 수 있도록 도와주는 도구이다.\n",
    "- (    )(이)(는) 라이브러리, 프레임워크, 툴킷 등과 같은 용어로 불리며, 머신러닝 기술을 사용해 필요한 기능을 빠르게 제공하고 편리한 인터페이스를 제공한다.\n",
    "- (    )은(는) 대부분 오픈소스로 제공되며, 다양한 언어로 자유롭게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 딥러닝 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 프레임워크 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 다음 보기 중 각 딥러닝 프레임워크에 알맞는 특징을 골라주세요.(각 2개씩) <br>\n",
    "#### (a) Google이 개발한 오픈소스 딥러닝 프레임워크입니다.\n",
    "#### (b) Meta(Facebook)이 개발한 오픈소스 딥러닝 프레임워크입니다.\n",
    "#### (c) TensorFlow, Theano, CNTK와 같은 백엔드 엔진과 함께 사용할 수 있습니다.\n",
    "#### (d) 어렵고 복잡하다는 TensorFlow의 문제를 해결하기 위해 개발되었습니다.\n",
    "#### (e) 데이터 플로우 그래프(Data Flow Graph)구조를 사용하는 특징이 있습니다.\n",
    "#### (f) 앞으로 비타민 딥러닝 세션에 계속 사용될 딥러닝 프레임워크입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.텐서플로우 : (a), (e) \n",
    "#### 2. 케라스 : (c), (d)\n",
    "#### 3. 파이토치 : (b), (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 2017년 기준 텐서플로우, 케라스, 파이토치를 점유율 순위대로 나열하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 :텐서플로우,케라스 ,파이토치 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 2023년 기준 텐서플로우, 케라스, 파이토치를 점유율 순위대로 나열하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 파이토치, 텐서플로우 , 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 다음 보기 중 텐서플로우의 장점이 아닌 것을 고르시오. <br>\n",
    "- (1) 구글에서 전폭적으로 지원하고 있기 때문에 지속적인 성능 개선과 지원에서 강점을 보인다.\n",
    "- (2) 추상화 수준이 높아 개발자가 알고리즘의 세세한 구현보다 전체적인 논리 자체에 더 집중할 수 있게 된다.\n",
    "- (3) 초보자와 전문가 모두 이해하기 쉬운 고수준 API를 제공하며, 다양한 백엔드 엔진을 지원한다.\n",
    "- (4) 대형 신경망 작업을 처리할 수 있는 높은 성능을 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 다음 보기 중 텐서플로우의 단점이 아닌 것을 고르시오. <br>\n",
    "- (1) 타 프레임워크에 비해 메모리를 효율적으로 사용하지 못한다.\n",
    "- (2) 타 프레임워크에 비해 속도가 느린 편이다.\n",
    "- (3) 딥러닝 모델을 만드는 데 기초 레벨부터 직접 작업해야 하기 때문에 초보자가 사용하기 어려울 수 있다.\n",
    "- (4) 파이토치와 비교하여 후발주자이기 때문에 점유율이 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : (4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 다음 보기 중 케라스의 장점이 아닌 것을 고르시오. <br>\n",
    "- (1) 일반 사용 사례에 최적화된 간단하고 일관된 인터페이스를 제공한다.\n",
    "- (2) 그래프를 만들면서 동시에 값을 할당하는 Define by run 방식으로 코드를 깔끔하고 직관적으로 작성할 수 있다.\n",
    "- (3) 케라스의 구성 요소는 모듈 형태로, 새로운 모델을 만들 때 각 모듈을 조합해 쉽게 새로운 모델을 만들 수 있다.\n",
    "- (4) 딥러닝 초급자도 각자 분야에서 손쉽게 딥러닝 모델을 개발하고 활용할 수 있도록 직관적인 API를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 다음 보기 중 케라스의 단점이 아닌 것을 고르시오. <br>\n",
    "- (1) 각 모듈이 종속적이기 때문에 관리가 어렵다.\n",
    "- (2) 모듈화의 한계로 복잡한 프로젝트의 구현 범위가 다소 좁은 편이다.\n",
    "- (3) 다양한 백엔드 위에서 동작하기 때문에 어떤 오류가 발생했을 때 케라스 자체의 문제인지, 백엔드 언어의 문제인지 특정하기 어렵다.\n",
    "- (4) 현재 텐서플로우, 케라스, 파이토치 중 점유율이 가장 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1 다음 보기 중 파이토치의 장점이 아닌 것을 고르시오. <br>\n",
    "- (1) Numpy를 대체하면서도 GPU를 이용한 연산이 가능하며 유연하고 빠르다.\n",
    "- (2) 절차가 간단하고 그래프가 동적으로 변화할 수 있으며 코드 자체도 파이썬과 유사해 진입 장벽이 낮은 편이다.\n",
    "- (3) 데이터 플로우 그래프를 통해 딥러닝 네트워크 표현이 직관적이다.\n",
    "- (4) 메모리에서 연산을 하면서도 신경망 사이즈를 최적으로 바꾸면서 동작시킬 수 있어 효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 파이토치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-1 <br>\n",
    "Output: <br>\n",
    "tensor([[1., 2.],\n",
    "        [3., 4.]], dtype=torch.float64)  <br>\n",
    "가 나오도록 빈칸을 채워주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1.,2.],[3.,4.]],dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-2  아래의 코드를 실행 후 tensor 와 Tensor가 어떤 점이 다른지 써주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2],[3,4]])\n",
    "Tensor = torch.Tensor([[1,2],[3,4]])\n",
    "print(tensor)\n",
    "print(Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) tensor는 리스트 안의 .은 제외하고 숫자만 인식한 반면 Tensor는 .까지 인식하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(3))\n",
    "print(torch.Tensor(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 입력받은 데이터를 복사해 사용하고, 입력받은 데이터를 메모리 공간으로 사용하는 차이가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.], requires_grad=True)\n",
      "tensor([2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([2.,3.], requires_grad=True))\n",
    "#print(torch.Tensor([2.,3.], requires_grad=True)) // 오류 발생\n",
    "print(torch.Tensor([2.,3.]).requires_grad_(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Tensor에서는 require_grad에 대한 매개변수가 존재하지 않는 듯 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "# print(torch.tensor()) // 오류 발생\n",
    "print(torch.Tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) tensor는 값을 입력하지 않으면 오류가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-3 차원이 다른 텐서들을 연산하기 위해서 차원을 바꾸려고 합니다. 아래의 코드를 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  5],\n",
      "        [ 6,  8, 10]])\n",
      "tensor([[ 0,  0, -1],\n",
      "        [ 1,  1,  0]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([[1,2,3],[3,4,5]])\n",
    "w = torch.tensor([[1,2],[2,3],[4,5]])\n",
    "\n",
    "w1=w.view(2,3)\n",
    "w2=w.permute(1,0)\n",
    "\n",
    "print(torch.add(v,w1))\n",
    "print(torch.sub(v,w2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-4 squeeze함수는 차원을 줄이는 , unsqueeze 함수는 차원을 늘리는 함수입니다. 아래의 코드를 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1인차원 없애기 : torch.Size([7, 46, 46])\n",
      "2번쨰 차원에 크기가 1인 차원 추가 : torch.Size([7, 1, 46, 46])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,7,46,46)\n",
    "x = x.squeeze()\n",
    "print(\"1인차원 없애기 :\", x.shape)\n",
    "\n",
    "\n",
    "x2 = torch.rand(7,46,46)\n",
    "x2 = x2.unsqueeze(dim=1)\n",
    "print(\"2번쨰 차원에 크기가 1인 차원 추가 :\", x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-1 첫번째 계산기로는 3+7을 하고 싶고, 두번째 계산기로는 3+10을 하고 싶어서 , 두 개의 계산기를 구현하고 싶어서, 두 개의 함수를 독립적으로 구현하였습니다. 이런 두개의 덧셈기를 클래스로 만드는 코드를 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "result1 = 0\n",
    "result2 = 0\n",
    "\n",
    "def add1(num):\n",
    "    global result1\n",
    "    result1 += num\n",
    "    return result1\n",
    "\n",
    "def add2(num):\n",
    "    global result2\n",
    "    result2 += num\n",
    "    return result2\n",
    "\n",
    "print(add1(3))\n",
    "print(add1(4))\n",
    "print(add2(3))\n",
    "print(add2(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "class Calculator:\n",
    "    def __init__(self):\n",
    "        self.result=0\n",
    "\n",
    "    def add(self, num):\n",
    "        self.result+=num\n",
    "        return self.result\n",
    "\n",
    "\n",
    "\n",
    "cal1 = Calculator()\n",
    "cal2 = Calculator()\n",
    "\n",
    "\n",
    "print(cal1.add(3))\n",
    "print(cal1.add(4))\n",
    "print(cal2.add(3))\n",
    "print(cal2.add(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-2  로지스틱 회귀를 클래스로 구현해보고 이를 학습 평가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-2-1 파이토치의 nn.Linear와 nn.Sigmoid로 로지스틱 회귀 구현하기위해서 아래의 코드를 채워주세요. <br>선형 레이어는 입력 특성의 차원이 2이고 출력 차원이 1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "   nn.Linear(2,1),\n",
    "   nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-2-2 위에서 구현한 코드를 토대로 로지스틱 회귀 모델은 클래스로 구현해주세요.\n",
    "<br>클래스 형태의 모델은 nn.Module을 상속받습니다.<br>그리고  __init__() 에서 모델에서 사용될 모듈 , 활성화 함수 등을 정의합니다. foward()에서는 모델에서 실행되어야하는 연산을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(2,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-3 학습을 통해 모델의 파라미터를 최적화하고, 정확도를 출력하여 모델의 성능을 평가해보도록 하겠습니다. <br> 다음의 조건에 맞게 코드를 채워주세요.\n",
    "<br>\n",
    "(a)\n",
    "<br>\n",
    "에폭은 500 으로 설정해주세요.\n",
    "<br>\n",
    "(b)\n",
    "<br>\n",
    "이진교차엔트로피를 사용하여 예측값과 y_train 간의 손실을 계산해주세요.\n",
    "<br>\n",
    "(c)\n",
    "<br>\n",
    "옵티마이저의 gradinet를 초기화하고\n",
    "<br>\n",
    "손실함수의 gradient 를 계산(역전파 학습)한뒤에\n",
    "<br>\n",
    "모델의 파라미터를 업데이트하도록 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/500 Cost: 1.141724 Accuracy 50.00%\n",
      "Epoch   10/500 Cost: 0.647589 Accuracy 83.33%\n",
      "Epoch   20/500 Cost: 0.618605 Accuracy 83.33%\n",
      "Epoch   30/500 Cost: 0.521262 Accuracy 83.33%\n",
      "Epoch   40/500 Cost: 0.434128 Accuracy 83.33%\n",
      "Epoch   50/500 Cost: 0.350855 Accuracy 83.33%\n",
      "Epoch   60/500 Cost: 0.273270 Accuracy 83.33%\n",
      "Epoch   70/500 Cost: 0.208481 Accuracy 83.33%\n",
      "Epoch   80/500 Cost: 0.167539 Accuracy 100.00%\n",
      "Epoch   90/500 Cost: 0.149163 Accuracy 100.00%\n",
      "Epoch  100/500 Cost: 0.138407 Accuracy 100.00%\n",
      "Epoch  110/500 Cost: 0.129377 Accuracy 100.00%\n",
      "Epoch  120/500 Cost: 0.121475 Accuracy 100.00%\n",
      "Epoch  130/500 Cost: 0.114501 Accuracy 100.00%\n",
      "Epoch  140/500 Cost: 0.108299 Accuracy 100.00%\n",
      "Epoch  150/500 Cost: 0.102748 Accuracy 100.00%\n",
      "Epoch  160/500 Cost: 0.097751 Accuracy 100.00%\n",
      "Epoch  170/500 Cost: 0.093229 Accuracy 100.00%\n",
      "Epoch  180/500 Cost: 0.089116 Accuracy 100.00%\n",
      "Epoch  190/500 Cost: 0.085360 Accuracy 100.00%\n",
      "Epoch  200/500 Cost: 0.081915 Accuracy 100.00%\n",
      "Epoch  210/500 Cost: 0.078744 Accuracy 100.00%\n",
      "Epoch  220/500 Cost: 0.075816 Accuracy 100.00%\n",
      "Epoch  230/500 Cost: 0.073103 Accuracy 100.00%\n",
      "Epoch  240/500 Cost: 0.070582 Accuracy 100.00%\n",
      "Epoch  250/500 Cost: 0.068233 Accuracy 100.00%\n",
      "Epoch  260/500 Cost: 0.066039 Accuracy 100.00%\n",
      "Epoch  270/500 Cost: 0.063986 Accuracy 100.00%\n",
      "Epoch  280/500 Cost: 0.062059 Accuracy 100.00%\n",
      "Epoch  290/500 Cost: 0.060248 Accuracy 100.00%\n",
      "Epoch  300/500 Cost: 0.058541 Accuracy 100.00%\n",
      "Epoch  310/500 Cost: 0.056931 Accuracy 100.00%\n",
      "Epoch  320/500 Cost: 0.055409 Accuracy 100.00%\n",
      "Epoch  330/500 Cost: 0.053968 Accuracy 100.00%\n",
      "Epoch  340/500 Cost: 0.052602 Accuracy 100.00%\n",
      "Epoch  350/500 Cost: 0.051304 Accuracy 100.00%\n",
      "Epoch  360/500 Cost: 0.050071 Accuracy 100.00%\n",
      "Epoch  370/500 Cost: 0.048896 Accuracy 100.00%\n",
      "Epoch  380/500 Cost: 0.047776 Accuracy 100.00%\n",
      "Epoch  390/500 Cost: 0.046708 Accuracy 100.00%\n",
      "Epoch  400/500 Cost: 0.045687 Accuracy 100.00%\n",
      "Epoch  410/500 Cost: 0.044711 Accuracy 100.00%\n",
      "Epoch  420/500 Cost: 0.043776 Accuracy 100.00%\n",
      "Epoch  430/500 Cost: 0.042880 Accuracy 100.00%\n",
      "Epoch  440/500 Cost: 0.042021 Accuracy 100.00%\n",
      "Epoch  450/500 Cost: 0.041196 Accuracy 100.00%\n",
      "Epoch  460/500 Cost: 0.040404 Accuracy 100.00%\n",
      "Epoch  470/500 Cost: 0.039641 Accuracy 100.00%\n",
      "Epoch  480/500 Cost: 0.038908 Accuracy 100.00%\n",
      "Epoch  490/500 Cost: 0.038202 Accuracy 100.00%\n",
      "Epoch  500/500 Cost: 0.037521 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs =500\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e726dfcfd2aa7c89c8dbc4c560c1e1f3c16eb0fa359096469343a30c0228cb32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
