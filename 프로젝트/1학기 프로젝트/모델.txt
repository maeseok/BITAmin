https://huggingface.co/beomi/kobert?library=true
40000 kobert

https://huggingface.co/monologg/kobert
실패

https://huggingface.co/beomi/kobert?library=true
흠

https://huggingface.co/kykim/bert-kor-base?library=true
정확도가 별로

https://huggingface.co/Helsinki-NLP/opus-mt-ko-en?library=true
그나마 낫지만 별로임

https://huggingface.co/dylanmengzhou/kobart-trans-en-ko-v2
별로임

https://huggingface.co/eenzeenee/t5-base-korean-summarization?library=true
10000까지
멍청

https://huggingface.co/KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-bidirection
10000까지
정확도 낮음


https://huggingface.co/EbanLee/kobart-summary-v3
20000
아직도 부족

https://huggingface.co/hyunwoongko/kobart
24000
정확도 낮음 - 그나마 나은듯

https://huggingface.co/monologg/kobigbird-bert-base?library=true
정확도 굉장히 낮음

https://huggingface.co/NHNDQ/nllb-finetuned-ko2en?library=true
5000
정확도 떨어짐


https://huggingface.co/kompactss/JeBERT_je_ko
이거 좋아보임