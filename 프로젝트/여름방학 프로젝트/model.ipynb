{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "book_embeddings = pd.read_csv('/kaggle/input/bookembedding/Book_Embedding_KoBERT.csv').values\n",
    "movie_embeddings = pd.read_csv('/kaggle/input/movieembedding/Movie_Embedding_KoBERT.csv').values\n",
    "book_data = pd.read_excel('/kaggle/input/book-data/Books_Data.xlsx')\n",
    "movie_data = pd.read_csv('/kaggle/input/moviedata/KoBERT_movie_keyword.csv')\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "book_embeddings = scaler.fit_transform(book_embeddings)\n",
    "movie_embeddings = scaler.fit_transform(movie_embeddings)\n",
    "\n",
    "# 텐서로 변환 및 평점 정규화\n",
    "book_embeddings = torch.tensor(book_embeddings, dtype=torch.float32)\n",
    "movie_embeddings = torch.tensor(movie_embeddings, dtype=torch.float32)\n",
    "book_ratings = torch.tensor(book_data['평점'].values, dtype=torch.float32)\n",
    "movie_ratings = torch.tensor(movie_data['평점'].values, dtype=torch.float32)\n",
    "\n",
    "# 평점 정규화\n",
    "book_ratings = (book_ratings - book_ratings.mean()) / book_ratings.std()\n",
    "movie_ratings = (movie_ratings - movie_ratings.mean()) / movie_ratings.std()\n",
    "\n",
    "# 평점과 임베딩 결합\n",
    "rating_weight = 1\n",
    "book_features = torch.cat([book_embeddings, book_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "movie_features = torch.cat([movie_embeddings, movie_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "\n",
    "# 트레인/테스트 데이터셋 분할\n",
    "train_movie_features, _, train_movie_ratings, _ = train_test_split(\n",
    "    movie_features, movie_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "train_book_features, _, train_book_ratings, _ = train_test_split(\n",
    "    book_features, book_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 책과 영화의 임베딩 차원 맞추기 (차원 일치)\n",
    "max_dim = max(train_movie_features.size(1), train_book_features.size(1))\n",
    "if train_movie_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_movie_features.size(1)\n",
    "    train_movie_features = torch.cat([train_movie_features, torch.zeros(train_movie_features.size(0), padding_size)], dim=1)\n",
    "if train_book_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_book_features.size(1)\n",
    "    train_book_features = torch.cat([train_book_features, torch.zeros(train_book_features.size(0), padding_size)], dim=1)\n",
    "\n",
    "# 임베딩 기반 유사도로 엣지 생성 함수\n",
    "def create_edges_based_on_embeddings(movie_embeddings, book_embeddings):\n",
    "    edge_index = []\n",
    "    num_movies = movie_embeddings.size(0)\n",
    "    num_books = book_embeddings.size(0)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    movie_embeddings = F.normalize(movie_embeddings, p=2, dim=1)\n",
    "    book_embeddings = F.normalize(book_embeddings, p=2, dim=1)\n",
    "    \n",
    "    similarity_matrix = torch.matmul(movie_embeddings, book_embeddings.t())\n",
    "    \n",
    "    # 각 영화에 대해 가장 유사한 도서를 찾고 엣지 생성\n",
    "    for movie_idx in range(num_movies):\n",
    "        best_book_idx = similarity_matrix[movie_idx].argmax().item()\n",
    "        edge_index.append([movie_idx, best_book_idx + num_movies])  # 영화 -> 도서 연결\n",
    "    \n",
    "    # 엣지 인덱스를 텐서로 변환하고 양방향 엣지 생성\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "# 엣지 생성 및 데이터 구성\n",
    "combined_edge_index = create_edges_based_on_embeddings(train_movie_features, train_book_features)\n",
    "\n",
    "# 그래프 데이터 구성\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = torch.cat([train_movie_features, train_book_features], dim=0).to(device)\n",
    "data_train = Data(x=x_train, edge_index=combined_edge_index.to(device))\n",
    "\n",
    "\n",
    "# 모델 + 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "book_embeddings = pd.read_csv('/kaggle/input/bookembedding/Book_Embedding_KoBERT.csv').values\n",
    "movie_embeddings = pd.read_csv('/kaggle/input/movieembedding/Movie_Embedding_KoBERT.csv').values\n",
    "book_data = pd.read_excel('/kaggle/input/book-data/Books_Data.xlsx')\n",
    "movie_data = pd.read_csv('/kaggle/input/moviedata/KoBERT_movie_keyword.csv')\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "book_embeddings = scaler.fit_transform(book_embeddings)\n",
    "movie_embeddings = scaler.fit_transform(movie_embeddings)\n",
    "\n",
    "# 텐서로 변환 및 평점 정규화\n",
    "book_embeddings = torch.tensor(book_embeddings, dtype=torch.float32)\n",
    "movie_embeddings = torch.tensor(movie_embeddings, dtype=torch.float32)\n",
    "book_ratings = torch.tensor(book_data['평점'].values, dtype=torch.float32)\n",
    "movie_ratings = torch.tensor(movie_data['평점'].values, dtype=torch.float32)\n",
    "\n",
    "# 평점 정규화\n",
    "book_ratings = (book_ratings - book_ratings.mean()) / book_ratings.std()\n",
    "movie_ratings = (movie_ratings - movie_ratings.mean()) / movie_ratings.std()\n",
    "\n",
    "# 평점과 임베딩 결합\n",
    "rating_weight = 1\n",
    "book_features = torch.cat([book_embeddings, book_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "movie_features = torch.cat([movie_embeddings, movie_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "\n",
    "# 트레인/테스트 데이터셋 분할\n",
    "train_movie_features, _, train_movie_ratings, _ = train_test_split(\n",
    "    movie_features, movie_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "train_book_features, _, train_book_ratings, _ = train_test_split(\n",
    "    book_features, book_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 책과 영화의 임베딩 차원 맞추기 (차원 일치)\n",
    "max_dim = max(train_movie_features.size(1), train_book_features.size(1))\n",
    "if train_movie_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_movie_features.size(1)\n",
    "    train_movie_features = torch.cat([train_movie_features, torch.zeros(train_movie_features.size(0), padding_size)], dim=1)\n",
    "if train_book_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_book_features.size(1)\n",
    "    train_book_features = torch.cat([train_book_features, torch.zeros(train_book_features.size(0), padding_size)], dim=1)\n",
    "\n",
    "# 임베딩 기반 유사도로 엣지 생성 함수\n",
    "def create_edges_based_on_embeddings(movie_embeddings, book_embeddings):\n",
    "    edge_index = []\n",
    "    num_movies = movie_embeddings.size(0)\n",
    "    num_books = book_embeddings.size(0)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    movie_embeddings = F.normalize(movie_embeddings, p=2, dim=1)\n",
    "    book_embeddings = F.normalize(book_embeddings, p=2, dim=1)\n",
    "    \n",
    "    similarity_matrix = torch.matmul(movie_embeddings, book_embeddings.t())\n",
    "    \n",
    "    # 각 영화에 대해 가장 유사한 도서를 찾고 엣지 생성\n",
    "    for movie_idx in range(num_movies):\n",
    "        best_book_idx = similarity_matrix[movie_idx].argmax().item()\n",
    "        edge_index.append([movie_idx, best_book_idx + num_movies])  # 영화 -> 도서 연결\n",
    "    \n",
    "    # 엣지 인덱스를 텐서로 변환하고 양방향 엣지 생성\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "# 엣지 생성 및 데이터 구성\n",
    "combined_edge_index = create_edges_based_on_embeddings(train_movie_features, train_book_features)\n",
    "\n",
    "# 그래프 데이터 구성\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = torch.cat([train_movie_features, train_book_features], dim=0).to(device)\n",
    "data_train = Data(x=x_train, edge_index=combined_edge_index.to(device))\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data\n",
    "\n",
    "dataset = GraphDataset(data_train)\n",
    "\n",
    "# 사용자 정의 collate 함수\n",
    "def custom_collate_fn(batch):\n",
    "    return batch[0]\n",
    "\n",
    "# 데이터 로더 초기화\n",
    "train_loader = DataLoader(dataset, batch_size=1, collate_fn=custom_collate_fn)\n",
    "\n",
    "# GAT 모델 정의\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GATNet, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.gat2 = GATConv(hidden_dim * 4, output_dim, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 모델 및 옵티마이저 초기화\n",
    "input_dim = x_train.size(1)\n",
    "hidden_dim = 64\n",
    "output_dim = input_dim\n",
    "\n",
    "model = GATNet(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 커스텀 손실 함수\n",
    "def custom_loss(output, target):\n",
    "    mse_loss = criterion(output, target)\n",
    "    penalty = torch.sum(torch.abs(output - target) ** 2) / output.size(0)\n",
    "    return mse_loss + 0.1 * penalty\n",
    "\n",
    "# 학습 루프\n",
    "model.train()\n",
    "for epoch in range(1, 501):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, edge_index)\n",
    "        loss = custom_loss(out, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 100 == 0:  # Logging more frequently for debugging\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n",
    "\n",
    "# 모델 저장\n",
    "checkpoint_path = 'checkpoint_gat.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': total_loss,\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"Model saved to {checkpoint_path}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Model evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Ensure all data is on the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move x_train and edge_index to the correct device\n",
    "x_train = x_train.to(device)\n",
    "combined_edge_index = combined_edge_index.to(device)\n",
    "\n",
    "# Run model inference\n",
    "with torch.no_grad():\n",
    "    output_embeddings = model(x_train, combined_edge_index)\n",
    "\n",
    "# Separate movie and book embeddings\n",
    "movie_embeddings_output = output_embeddings[:train_movie_features.size(0)]\n",
    "book_embeddings_output = output_embeddings[train_movie_features.size(0):]\n",
    "\n",
    "# Move tensors to CPU for cosine similarity calculation\n",
    "movie_embeddings_output_cpu = movie_embeddings_output.cpu()\n",
    "book_embeddings_output_cpu = book_embeddings_output.cpu()\n",
    "\n",
    "# Calculate cosine similarity on the CPU\n",
    "similarity_matrix = cosine_similarity(movie_embeddings_output_cpu, book_embeddings_output_cpu)\n",
    "\n",
    "# Implementing a diversity-aware recommendation\n",
    "top_k_books = 5  # Number of books to recommend per movie\n",
    "recommendations = {}\n",
    "used_books = set()  # Track used books to promote diversity\n",
    "\n",
    "for movie_idx in range(similarity_matrix.shape[0]):\n",
    "    # Get sorted indices based on similarity scores\n",
    "    sorted_indices = similarity_matrix[movie_idx].argsort()[::-1]\n",
    "    \n",
    "    # Filter out already recommended books\n",
    "    diverse_recommendations = []\n",
    "    for idx in sorted_indices:\n",
    "        if idx not in used_books:\n",
    "            diverse_recommendations.append(idx)\n",
    "        if len(diverse_recommendations) == top_k_books:\n",
    "            break\n",
    "\n",
    "    # Update the recommendations and the set of used books\n",
    "    recommendations[movie_idx] = diverse_recommendations\n",
    "    used_books.update(diverse_recommendations)\n",
    "\n",
    "# Save recommendations to an Excel file\n",
    "book_titles = book_data['도서명'].values\n",
    "movie_titles = movie_data['제목'].values\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for movie_idx, book_indices in recommendations.items():\n",
    "    for book_idx in book_indices:\n",
    "        recommendation_list.append({\n",
    "            '영화명': movie_titles[movie_idx],\n",
    "            '추천 도서명': book_titles[book_idx],\n",
    "            '유사도': similarity_matrix[movie_idx, book_idx]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendation_df = pd.DataFrame(recommendation_list)\n",
    "\n",
    "# Save to Excel\n",
    "output_excel_path = 'book_recommendations.xlsx'\n",
    "recommendation_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Recommendations saved to {output_excel_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return batch[0]\n",
    "\n",
    "dataset = GraphDataset(data_train)\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# GAT 모델 정의\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GATNet, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.gat2 = GATConv(hidden_dim * 4, output_dim, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 모델 및 옵티마이저 초기화\n",
    "input_dim = x_train.size(1)\n",
    "hidden_dim = 64\n",
    "output_dim = input_dim\n",
    "\n",
    "model = GATNet(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 패널티 기반 손실 함수\n",
    "def custom_loss(output, target):\n",
    "    mse_loss = criterion(output, target)\n",
    "    penalty = torch.sum(torch.abs(output - target) ** 2) / output.size(0)\n",
    "    return mse_loss + 0.1 * penalty\n",
    "\n",
    "# 학습 루프\n",
    "model.train()\n",
    "for epoch in range(1, 2001):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, edge_index)\n",
    "        loss = custom_loss(out, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n",
    "\n",
    "# 모델 저장\n",
    "checkpoint_path = 'checkpoint_gat.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': total_loss,\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"모델이 {checkpoint_path}에 저장되었습니다.\")\n",
    "\n",
    "# movie_features와 movie_edge_index 정의하기\n",
    "# 예시: movie_features는 영화의 특징을 담는 tensor, movie_edge_index는 영화 간의 연결을 나타내는 tensor\n",
    "movie_features = torch.tensor(x_movie, dtype=torch.float).to(device)  # 영화 특징\n",
    "movie_edge_index = torch.tensor(edge_index_movie, dtype=torch.long).to(device)  # 영화 간의 엣지 인덱스\n",
    "\n",
    "# 영화 임베딩 생성\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    movie_embeddings = model(movie_features, movie_edge_index)\n",
    "\n",
    "# 추천 함수 (영화 -> 도서)\n",
    "def recommend_books_for_movie(movie_idx, top_n=1):\n",
    "    movie_embedding = movie_embeddings[movie_idx].unsqueeze(0)\n",
    "    similarities = F.cosine_similarity(movie_embedding, book_embeddings).cpu().numpy()\n",
    "    \n",
    "    # 대출 건수 기반 패널티 적용\n",
    "    loan_counts = book_data['대출건수'].values\n",
    "    weighted_similarities = similarities - 0.01 * loan_counts\n",
    "    \n",
    "    # 추천된 도서의 인덱스를 필터링하지 않고 점수 조정\n",
    "    top_indices = np.argpartition(-weighted_similarities, top_n)[:top_n]\n",
    "    top_indices = top_indices[np.argsort(-weighted_similarities[top_indices])]\n",
    "    \n",
    "    recommended_books = book_data.iloc[top_indices]\n",
    "    return recommended_books, top_indices\n",
    "\n",
    "# 모든 영화에 대해 추천 생성\n",
    "all_recommendations = []\n",
    "recommendation_history = {}\n",
    "\n",
    "for movie_idx in range(movie_features.size(0)):\n",
    "    movie_title = movie_data.iloc[movie_idx]['제목']\n",
    "    \n",
    "    # 이미 추천된 도서 목록 초기화\n",
    "    already_recommended = set(recommendation_history.get(movie_idx, []))\n",
    "    \n",
    "    # 영화에 대한 도서 추천\n",
    "    recommended_books, top_indices = recommend_books_for_movie(movie_idx)\n",
    "    \n",
    "    # 추천 도서의 중복 방지\n",
    "    for idx in top_indices:\n",
    "        if idx not in already_recommended:\n",
    "            book = book_data.iloc[idx]\n",
    "            all_recommendations.append({\n",
    "                'Movie Title': movie_title,\n",
    "                'Book Title': book['도서명'],\n",
    "                'Author': book['저자명'],\n",
    "                'Publisher': book['출판사']\n",
    "            })\n",
    "            already_recommended.add(idx)\n",
    "    \n",
    "    # 추천된 도서 기록 업데이트\n",
    "    recommendation_history[movie_idx] = list(already_recommended)\n",
    "\n",
    "# 추천 결과를 Excel로 저장\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "recommendations_df.to_excel('movie_book_recommendations_gat.xlsx', index=False)\n",
    "print(\"Recommendations saved to 'movie_book_recommendations_gat.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return batch[0]\n",
    "\n",
    "dataset = GraphDataset(data_train)\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 설정\n",
    "input_dim = x_train.size(1)  # 입력 차원 설정\n",
    "hidden_dim = 64  # 중간 계층 크기 설정\n",
    "output_dim = input_dim  # 출력 차원은 입력 차원과 동일하게 설정\n",
    "\n",
    "# GraphSAGE 모델 정의\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGENet, self).__init__()\n",
    "        self.sage1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.sage2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.sage2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 모델 및 옵티마이저 초기화\n",
    "model = GraphSAGENet(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 패널티 기반 손실 함수\n",
    "def custom_loss(output, target):\n",
    "    mse_loss = criterion(output, target)\n",
    "    # 반복되는 도서에 패널티 부여\n",
    "    penalty = torch.sum(torch.abs(output - target) ** 2) / output.size(0)\n",
    "    return mse_loss + 0.1 * penalty\n",
    "\n",
    "# 학습 루프\n",
    "model.train()\n",
    "for epoch in range(1, 5001):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, edge_index)\n",
    "        loss = custom_loss(out, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n",
    "\n",
    "# 모델 저장\n",
    "checkpoint_path = 'checkpoint_sage.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': total_loss,\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"모델이 {checkpoint_path}에 저장되었습니다.\")\n",
    "\n",
    "# 추천 함수 (영화 -> 도서)\n",
    "def recommend_books_for_movie(movie_idx):\n",
    "    movie_embedding = movie_embeddings[movie_idx].unsqueeze(0)\n",
    "    similarities = F.cosine_similarity(movie_embedding, book_embeddings).cpu().numpy()\n",
    "    \n",
    "    top_index = np.argmax(similarities)\n",
    "    recommended_book = book_data.iloc[[top_index]]  # DataFrame으로 반환\n",
    "    \n",
    "    return recommended_book\n",
    "\n",
    "# 모든 영화에 대해 추천 생성\n",
    "all_recommendations = []\n",
    "\n",
    "for movie_idx in range(movie_features.size(0)):  # 영화 개수\n",
    "    movie_title = movie_data.iloc[movie_idx]['제목']\n",
    "    recommended_book = recommend_books_for_movie(movie_idx)\n",
    "    \n",
    "    all_recommendations.append({\n",
    "        'Movie Title': movie_title,\n",
    "        'Book Title': recommended_book['도서명'].values[0],\n",
    "        'Author': recommended_book['저자명'].values[0],\n",
    "        'Publisher': recommended_book['출판사'].values[0]\n",
    "    })\n",
    "\n",
    "# 추천 결과를 Excel로 저장\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "recommendations_df.to_excel('movie_book_recommendations_sage.xlsx', index=False)\n",
    "print(\"Recommendations saved to 'movie_book_recommendations_sage.xlsx'\")\n",
    "\n",
    "# 도서 추천 횟수 계산\n",
    "book_recommendation_count = pd.DataFrame(all_recommendations)['Book Title'].value_counts()\n",
    "recommendation_counts_df = pd.DataFrame({\n",
    "    'Book Title': book_recommendation_count.index,\n",
    "    'Recommendation Count': book_recommendation_count.values\n",
    "}).sort_values(by='Recommendation Count', ascending=False)\n",
    "\n",
    "# 도서 추천 횟수 Excel로 저장\n",
    "recommendation_counts_df.to_excel('book_recommendation_counts_sage.xlsx', index=False)\n",
    "print(\"Book recommendation counts saved to 'book_recommendation_counts_sage.xlsx'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
