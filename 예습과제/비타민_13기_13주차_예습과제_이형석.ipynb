{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "QziHwl-vAkug",
      "metadata": {
        "id": "QziHwl-vAkug"
      },
      "source": [
        "# **2조**\n",
        "**신경망 (활성화함수(시그모이드, ReLU등), 다차원 배열의 계산, 다층 신경망 구현, 출력층 설계)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6483e4",
      "metadata": {
        "id": "2e6483e4"
      },
      "source": [
        "## 1.활성화 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc388440",
      "metadata": {
        "id": "cc388440"
      },
      "source": [
        "1. 활성화 함수를 비선형 함수로 구현하는 이유를 간략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3784089",
      "metadata": {
        "id": "c3784089"
      },
      "source": [
        "설명: 단층 퍼셉트론이 XOR 문제와 같은 비선형 문제를 해결할 수 없는 한계를 극복하는 등의 장점이 있어 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e449264f",
      "metadata": {
        "id": "e449264f"
      },
      "source": [
        "아래 코드를 실행해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "af0c667e",
      "metadata": {
        "id": "af0c667e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9740f90b",
      "metadata": {
        "id": "9740f90b"
      },
      "source": [
        "2. 아래 시그모이드 함수 구현 코드(??? 부분)를 완성하고 시그모이드 함수에 대해서 간략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0e4d154b",
      "metadata": {
        "id": "0e4d154b",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m-\u001b[39m\u001b[39m5.\u001b[39m, \u001b[39m5.\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(x)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mplot(x\u001b[39m.\u001b[39;49mnumpy(), y\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "x = torch.arange(-5., 5., 0.1)\n",
        "y = torch.sigmoid(x)\n",
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629f1a34",
      "metadata": {
        "id": "629f1a34"
      },
      "source": [
        "설명: 시그모이드 함수는 입력값을 0과 1 사이의 값으로 변환하는 비선형 활성화 함수입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93dadf76",
      "metadata": {
        "id": "93dadf76"
      },
      "source": [
        "3. 아래 하이퍼볼릭탄젠트 함수 구현 코드를 완성하고 하이퍼볼릭탄젠트 함수에 대해서 간략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52b42834",
      "metadata": {
        "id": "52b42834"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6148\\612086185.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  x = torch.range(-5., 5., 0.1)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrange(\u001b[39m-\u001b[39m\u001b[39m5.\u001b[39m, \u001b[39m5.\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(x)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mplot(x\u001b[39m.\u001b[39;49mnumpy(), y\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "x = torch.range(-5., 5., 0.1)\n",
        "y = torch.tanh(x)\n",
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11918a7",
      "metadata": {
        "id": "f11918a7"
      },
      "source": [
        "설명:하이퍼볼릭 탄젠트 함수(tanh 함수)는 또 다른 비선형 활성화 함수로, 시그모이드 함수와 유사하지만 출력 값이 -1과 1 사이에 있습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41959663",
      "metadata": {
        "id": "41959663"
      },
      "source": [
        "4. 시그모이드 함수를 사용할 때 나타나는 그래디언트 소실 문제에 대해 산략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55aa1aa5",
      "metadata": {
        "id": "55aa1aa5"
      },
      "source": [
        "설명:그래디언트 소실 문제는 신경망의 역전파 과정에서 발생하는 문제로, 특히 깊은 신경망에서 자주 발생합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1237f0c2",
      "metadata": {
        "id": "1237f0c2"
      },
      "source": [
        "5. 아래 렐루 함수 구현 코드를 완성하고 렐루 함수의 장점과 단점에 대해서 간략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2fcff64a",
      "metadata": {
        "id": "2fcff64a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6148\\1463588837.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  x = torch.range(-5., 5., 0.1)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrange(\u001b[39m-\u001b[39m\u001b[39m5.\u001b[39m, \u001b[39m5.\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m      3\u001b[0m y\u001b[39m=\u001b[39mrelu(x)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(x\u001b[39m.\u001b[39;49mnumpy(), y\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "relu = torch.nn.ReLU()\n",
        "x = torch.range(-5., 5., 0.1)\n",
        "y=relu(x)\n",
        "plt.plot(x.numpy(), y.numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbd93af",
      "metadata": {
        "id": "bfbd93af"
      },
      "source": [
        "설명: "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73a5128",
      "metadata": {
        "id": "a73a5128"
      },
      "source": [
        "6. 아래 소프트맥스 함수 구현 코드를 완성하고 소프트맥스 함수에 대해서 간략히 설명해주세요. (4점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84efef4",
      "metadata": {
        "id": "f84efef4"
      },
      "outputs": [],
      "source": [
        "softmax = torch.nn.softmax(dim=1)\n",
        "x_input = torch.randn(1,3)\n",
        "y_output = softmax(x_input)\n",
        "print(x_input)\n",
        "print(y_output)\n",
        "print(torch.sum(y_output, dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ee003f",
      "metadata": {
        "id": "31ee003f"
      },
      "source": [
        "설명: 입력받은 값들을 각 클래스에 대한 확률값으로 변환해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a3f78d",
      "metadata": {
        "id": "a2a3f78d"
      },
      "source": [
        "## 2. 다차원배열계산, 다층신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9914e0cb",
      "metadata": {
        "id": "9914e0cb"
      },
      "source": [
        "1. 아래 2차원 텐서를 구현하는 코드를 완성해주세요. (3점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "889cd32a",
      "metadata": {
        "id": "889cd32a"
      },
      "outputs": [],
      "source": [
        "tensor_torch1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor_torch2 = torch.tensor([[1, 2, 3], [4, 5, 6]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f05396b5",
      "metadata": {
        "id": "f05396b5"
      },
      "source": [
        "2. 텐서 간의 곱셈, 행렬곱셈, (3,2)로의 차원변경을 수행하는 코드를 완성해주세요. (3점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ad6430bb",
      "metadata": {
        "id": "ad6430bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  4,  9],\n",
              "        [16, 25, 36]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_mul_torch = torch.mul(tensor_torch1, tensor_torch2)\n",
        "tensor_mul_torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "38c2e53b",
      "metadata": {
        "id": "38c2e53b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[22, 28],\n",
              "        [49, 64]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_matmul_torch = torch.matmul(tensor_torch1, tensor_torch2.view(3,2))\n",
        "tensor_matmul_torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0186e0",
      "metadata": {
        "id": "0c0186e0"
      },
      "source": [
        "3. 아래 다층신경망의 데이터 준비 코드를 실행하고 코드에 대해 자유롭게 설명해주세요. (5점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436238c5",
      "metadata": {
        "id": "436238c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터셋 변환 정의\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoader 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5eab9b7",
      "metadata": {
        "id": "e5eab9b7"
      },
      "source": [
        "설명: MNIST 데이터셋 가져와서 데이터셋 준비하는 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16182c5c",
      "metadata": {
        "id": "16182c5c"
      },
      "source": [
        "4. 아래 다층신경망의 모델 정의 코드를 실행하고 코드에 대해 자유롭게 설명해주세요. (5점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176570b0",
      "metadata": {
        "id": "176570b0"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "608d700d",
      "metadata": {
        "id": "608d700d"
      },
      "source": [
        "설명: 다층 신경망 모델을 정의하고, 이를 통해 MNIST 데이터셋을 분류하는 준비를 마칩니다. 모델은 네 개의 fully connected 레이어로 구성되어 있으며, 각 레이어 사이에는 ReLU 활성화 함수가 적용됩니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791e4b79",
      "metadata": {
        "id": "791e4b79"
      },
      "source": [
        "5. 아래 다층신경망의 모델 훈련 코드를 실행하고 코드에 대해 자유롭게 설명해주세요. (실행 시간이 오래 걸립니다) (5점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe3750b",
      "metadata": {
        "id": "cbe3750b"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        # 모델 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7affdca5",
      "metadata": {
        "id": "7affdca5"
      },
      "source": [
        "설명: 모델을 불러와 5epoch 학습하는 코드입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e3d720f",
      "metadata": {
        "id": "2e3d720f"
      },
      "source": [
        "6. 아래 다층신경망의 모델 평가 코드를 실행하고 코드에 대해 자유롭게 설명해주세요. (5점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a788bbe",
      "metadata": {
        "id": "6a788bbe"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e2ecad5",
      "metadata": {
        "id": "1e2ecad5"
      },
      "source": [
        "설명:학습된 모델의 성능을 평가하고, 모델이 테스트 데이터셋에서 얼마나 잘 동작하는지를 판단하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1GkkGz-bAid8",
      "metadata": {
        "id": "1GkkGz-bAid8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKRLrxwRA6uh",
      "metadata": {
        "id": "tKRLrxwRA6uh"
      },
      "source": [
        "# **3조**\n",
        "**신경망 학습(손실 함수, 수치 미분(편미분), 기울기(경사 하강법))**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sd4Mce6gBBZF",
      "metadata": {
        "id": "sd4Mce6gBBZF"
      },
      "source": [
        "##1. 손실함수와 수치미분(편미분) - 총 25점\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D2NuQhnGBEwt",
      "metadata": {
        "id": "D2NuQhnGBEwt"
      },
      "source": [
        "### **1.1) 다음의 문장을 완성하시오.(5점, 각 1점씩)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r6qDReSFBIHa",
      "metadata": {
        "id": "r6qDReSFBIHa"
      },
      "source": [
        "손실 함수는 신경망 성능의 '???'을 나타내는 지표로, 현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 '???'하느냐를 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sW-YMLFeBJCA",
      "metadata": {
        "id": "sW-YMLFeBJCA"
      },
      "source": [
        "손실 함수는 신경망 성능의 '???'을 나타내는 지표로, 현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 '???'하느냐를 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IHkofEhnBKuZ",
      "metadata": {
        "id": "IHkofEhnBKuZ"
      },
      "source": [
        " 가장 많이 쓰이는 손실 함수는 크로스엔트로피 손실 함수입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KiIAvIpiBLTj",
      "metadata": {
        "id": "KiIAvIpiBLTj"
      },
      "source": [
        "평균 제곱 오차는 각 원소의 출력(추정 값)과 정답 레이블(참 값)의 차를 제곱한 후, 그 평균을 구합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fkB9Ji3EBNOt",
      "metadata": {
        "id": "fkB9Ji3EBNOt"
      },
      "source": [
        "원소의 출력(추정 값)과 정답 레이블(참 값)의 차가 작으면 작을 수록 ???."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ivlJ04xlBO0F",
      "metadata": {
        "id": "ivlJ04xlBO0F"
      },
      "source": [
        "### **1.2)  *평균 제곱 오차* 함수를 완성하시오. (5점)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8a3ucZs3Ai9Q",
      "metadata": {
        "id": "8a3ucZs3Ai9Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.009750000000000003\n",
            "0.059750000000000004\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_squared_error(y, t):\n",
        "    return 0.5 * np.mean((y - t)**2)\n",
        "\n",
        "\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "\n",
        "print( mean_squared_error(np.array(y1), np.array(t)) )\n",
        "# >>> 0.0975000000031\n",
        "\n",
        "\n",
        "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print( mean_squared_error(np.array(y2), np.array(t)) )\n",
        "# >>> 0.597500000003"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NGOOLNi0BVp_",
      "metadata": {
        "id": "NGOOLNi0BVp_"
      },
      "source": [
        "모범 답안)<br>\n",
        "0.09750000000000003<br>\n",
        "0.5975\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J3uqsun_Bbsu",
      "metadata": {
        "id": "J3uqsun_Bbsu"
      },
      "source": [
        "### **1.3)   *교차 엔트로피 오차* 함수를 완성하시오. (5점)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "QycsAvUoBago",
      "metadata": {
        "id": "QycsAvUoBago"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ]
        }
      ],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))\n",
        "\n",
        "\n",
        "\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "\n",
        "print( cross_entropy_error(np.array(y1), np.array(t)) )\n",
        " # >>> 0.5108254709933802\n",
        "\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "\n",
        "print( cross_entropy_error(np.array(y2), np.array(t) ))\n",
        " # >>> 2.3025840929945458"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lqr8AcoGBgvO",
      "metadata": {
        "id": "Lqr8AcoGBgvO"
      },
      "source": [
        "모범 답안)<br>\n",
        "0.510825457099338<br>\n",
        "2.302584092994546"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PwCvhfoiBkoI",
      "metadata": {
        "id": "PwCvhfoiBkoI"
      },
      "source": [
        "### **1.4) 신경망 학습에서 손실 함수를 설정하는 이유를 서술하시오. (5점)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hiwZbuBxBmWL",
      "metadata": {
        "id": "hiwZbuBxBmWL"
      },
      "source": [
        "답안) 학습 과정에서 모델이 얼마나 잘 동작하는지를 평가하고, 이를 통해 모델을 최적화하기 위한 방향을 제시하기 위함입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XeNAR6-bBoM5",
      "metadata": {
        "id": "XeNAR6-bBoM5"
      },
      "source": [
        "### **1.5) 다음의 문장을 완성하시오.(5점)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HlgZaXtrBqe0",
      "metadata": {
        "id": "HlgZaXtrBqe0"
      },
      "source": [
        "**수치미분이란?**\n",
        "\n",
        " '해석적 미분'은 우리가 수학 시간에 배운 오차를 포함하지 않는 '진정한 미분' 값을 구해줍니다. '수치 미분'은 이를 '근사적'로 계산하는 방법입니다. 따라서 오차가 포함됩니다.\n",
        "\n",
        "\n",
        "**편미분이란?**\n",
        "\n",
        " 편미분은 변수가 여러 개인 함수에 대한 미분을 의미합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gcjinaerBr0H",
      "metadata": {
        "id": "gcjinaerBr0H"
      },
      "source": [
        "##2. 기울기 (경사 하강법) - 총 25점"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hDYLWiB1BvOT",
      "metadata": {
        "id": "hDYLWiB1BvOT"
      },
      "source": [
        "### **2.1) 경사 하강법(Gradient Descent)이란 무엇인가요? 간략하게 서술해주세요. (3점)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T8OeYH0mBwua",
      "metadata": {
        "id": "T8OeYH0mBwua"
      },
      "source": [
        "답안) 경사 하강법은 현재 위치에서의 기울기(경사)를 계산하여 그 기울기가 가리키는 방향으로 조금씩 이동하면서 손실 함수의 최솟값을 찾는 방법입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y0ghdNRaBySQ",
      "metadata": {
        "id": "y0ghdNRaBySQ"
      },
      "source": [
        "### **2.2) 경사 하강법의 대표적인 3가지 종류에 대해 각각 설명하고, 차이점을 설명하세요. (5점)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fjpaN6gB0iC",
      "metadata": {
        "id": "0fjpaN6gB0iC"
      },
      "source": [
        "배치 경사 하강법: 배치 경사 하강법은 한 번의 파라미터 업데이트를 위해 전체 훈련 데이터셋을 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1hljsSsmB1dy",
      "metadata": {
        "id": "1hljsSsmB1dy"
      },
      "source": [
        "확률적 경사 하강법: 매 반복마다 하나의 훈련 데이터 포인트를 사용하여 그래디언트를 계산합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xj9dVDFNB2Y2",
      "metadata": {
        "id": "Xj9dVDFNB2Y2"
      },
      "source": [
        "미니배치 경사 하강법: 미니배치 경사 하강법은 배치 경사 하강법과 확률적 경사 하강법의 절충안입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Hd7vwdQB3Wv",
      "metadata": {
        "id": "1Hd7vwdQB3Wv"
      },
      "source": [
        "### **2.3) 단순 선형 회귀를 위한 Full batch 경사하강법 예제 코드입니다. 빈칸을 채워주세요. (5점)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "FsZcFEsUBjWN",
      "metadata": {
        "id": "FsZcFEsUBjWN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최종 theta 값: [[3.88738081]\n",
            " [3.12221329]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "theta = np.random.randn(2, 1)\n",
        "learning_rate = 0.1\n",
        "iterations = 1000\n",
        "m = len(X)\n",
        "\n",
        "def gradient_descent(X_b, y, theta, learning_rate, iterations):\n",
        "    for iteration in range(iterations):\n",
        "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "        theta = theta - learning_rate * gradients\n",
        "    return theta\n",
        "\n",
        "X_b = np.c_[np.ones((m, 1)), X]\n",
        "\n",
        "theta_final = gradient_descent(X_b, y, theta, learning_rate, iterations)\n",
        "\n",
        "print(\"최종 theta 값:\", theta_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yp2kU6wMB5-U",
      "metadata": {
        "id": "Yp2kU6wMB5-U"
      },
      "source": [
        "모범 답안)<br>\n",
        "최종 theta 값: [[3.79452122]<br>\n",
        " [3.1510319 ]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2hv3NEyLB-_a",
      "metadata": {
        "id": "2hv3NEyLB-_a"
      },
      "source": [
        "### **2.4) 단순 선형 회귀를 위한 Stochastic 경사하강법 예제 코드입니다. 빈칸을 채워주세요. (5점)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "Pn5iFSfwB64_",
      "metadata": {
        "id": "Pn5iFSfwB64_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m = 1.9999999980394758, b = 8.312333324872471e-09\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "m, b = 0, 0\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "for _ in range(iterations):\n",
        "    for i in range(len(X)):\n",
        "        y_pred = m * X[i] + b\n",
        "        error = y_pred - y[i]\n",
        "        m_grad = 2 * X[i] * error\n",
        "        b_grad = 2 * error\n",
        "        m -= learning_rate * m_grad\n",
        "        b -= learning_rate * b_grad\n",
        "\n",
        "print(f\"m = {m}, b = {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yz-qpOFwCB0P",
      "metadata": {
        "id": "Yz-qpOFwCB0P"
      },
      "source": [
        "모범 답안)<br>\n",
        "m = 1.9999999980394758, b = 8.312333324872471e-09\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9-ECF_DKCFUi",
      "metadata": {
        "id": "9-ECF_DKCFUi"
      },
      "source": [
        "### **2.5) 2차 다항 회귀를 위한 Mini batch 경사하강법 에제 코드입니다. 빈칸을 채워주세요. (7점)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "jZWpocNcCEGc",
      "metadata": {
        "id": "jZWpocNcCEGc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최종 theta 값: [[3.93512952]\n",
            " [2.78872744]\n",
            " [1.99632765]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + 2 * X**2 + np.random.randn(100, 1)\n",
        "\n",
        "X_poly = np.c_[X, X**2]\n",
        "\n",
        "theta = np.random.randn(3, 1)\n",
        "learning_rate = 0.1\n",
        "iterations = 1000\n",
        "batch_size = 20\n",
        "m = len(X_poly)\n",
        "\n",
        "def mini_batch_gradient_descent(X_b, y, theta, learning_rate, iterations, batch_size):\n",
        "    for iteration in range(iterations):\n",
        "        shuffled_indices = np.random.permutation(m)\n",
        "        X_b_shuffled = X_b[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        for i in range(0, m, batch_size):\n",
        "            X_i = X_b_shuffled[i:i+batch_size]\n",
        "            y_i = y_shuffled[i:i+batch_size]\n",
        "            gradients = 2/batch_size * X_i.T.dot(X_i.dot(theta) - y_i)\n",
        "            theta = theta - learning_rate * gradients\n",
        "    return theta\n",
        "\n",
        "X_b = np.c_[np.ones((m, 1)), X_poly]\n",
        "\n",
        "theta_final = mini_batch_gradient_descent(X_b, y, theta, learning_rate, iterations, batch_size)\n",
        "\n",
        "print(\"최종 theta 값:\", theta_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fv_IW7pcCHxr",
      "metadata": {
        "id": "fv_IW7pcCHxr"
      },
      "source": [
        "모범 답안)<br>\n",
        "최종 theta 값: [[4.02673618]<br>\n",
        " [3.18859894]<br>\n",
        " [1.9938976 ]]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
